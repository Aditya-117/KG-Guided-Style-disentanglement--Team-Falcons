{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-login"
      },
      "source": [
        "## **Step 0**: Log in to Hugging Face (Required)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting huggingface_hub\n",
            "  Using cached huggingface_hub-1.1.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from huggingface_hub) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from huggingface_hub) (2025.9.0)\n",
            "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub)\n",
            "  Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from huggingface_hub)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from huggingface_hub) (25.0)\n",
            "Collecting pyyaml>=5.1 (from huggingface_hub)\n",
            "  Using cached pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
            "Collecting shellingham (from huggingface_hub)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting typer-slim (from huggingface_hub)\n",
            "  Using cached typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from huggingface_hub) (4.15.0)\n",
            "Collecting anyio (from httpx<1,>=0.23.0->huggingface_hub)\n",
            "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->huggingface_hub)\n",
            "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface_hub)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting idna (from httpx<1,>=0.23.0->huggingface_hub)\n",
            "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Collecting click>=8.0.0 (from typer-slim->huggingface_hub)\n",
            "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->huggingface_hub)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Using cached huggingface_hub-1.1.2-py3-none-any.whl (514 kB)\n",
            "Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
            "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
            "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
            "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
            "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: tqdm, sniffio, shellingham, pyyaml, idna, hf-xet, h11, click, certifi, typer-slim, httpcore, anyio, httpx, huggingface_hub\n",
            "Successfully installed anyio-4.11.0 certifi-2025.10.5 click-8.3.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface_hub-1.1.2 idna-3.11 pyyaml-6.0.3 shellingham-1.5.4 sniffio-1.3.1 tqdm-4.67.1 typer-slim-0.20.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipywidgets\n",
            "  Using cached ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
            "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipywidgets) (9.7.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
            "  Using cached widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
            "  Using cached jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: colorama>=0.4.4 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
            "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Using cached ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
            "Using cached jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
            "Using cached widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
            "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
            "Successfully installed ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 widgetsnbextension-4.0.15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (1.1.2)\n",
            "Collecting accelerate\n",
            "  Using cached accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from transformers) (3.19.1)\n",
            "Collecting huggingface_hub\n",
            "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from transformers) (2.3.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Using cached regex-2025.11.3-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
            "Collecting requests (from transformers)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
            "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from huggingface_hub) (2025.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from accelerate) (7.1.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: networkx in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
            "  Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata (38 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from requests->transformers) (3.11)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cse iit bhilai\\documents\\team_falcons_ir_final year\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
            "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
            "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "Using cached accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
            "Using cached regex-2025.11.3-cp311-cp311-win_amd64.whl (277 kB)\n",
            "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
            "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Installing collected packages: urllib3, safetensors, regex, charset_normalizer, requests, huggingface_hub, tokenizers, accelerate, transformers\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface_hub 1.1.2\n",
            "    Uninstalling huggingface_hub-1.1.2:\n",
            "      Successfully uninstalled huggingface_hub-1.1.2\n",
            "Successfully installed accelerate-1.11.0 charset_normalizer-3.4.4 huggingface_hub-0.36.0 regex-2025.11.3 requests-2.32.5 safetensors-0.6.2 tokenizers-0.22.1 transformers-4.57.1 urllib3-2.5.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub\n",
        "!pip install ipywidgets\n",
        "!pip install --upgrade transformers huggingface_hub accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "670912f90cf6451f97f77f3a008e69e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# You must log in again in a new notebook\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-install"
      },
      "source": [
        "## **Step 1**: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch scikit-learn accelerate tqdm pandas openpyxl rouge-score nltk matplotlib -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-imports"
      },
      "source": [
        "## **Step 2**: Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "from typing import List, Dict, Tuple, Callable, Optional\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "# --- Import Scoring Libraries ---\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-generator"
      },
      "source": [
        "## **Step 3**: Lightweight Model Wrapper (Generation Only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelGenerator:\n",
        "    def __init__(self, model_name: str):\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        self.device = self.model.device\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        self._layers_attr_path = self._find_layer_attr_path()\n",
        "        self.num_layers = len(self._get_layers_list())\n",
        "        print(f\"[ModelGenerator] Model loaded. Path: {self._layers_attr_path}, Layers: {self.num_layers}\")\n",
        "\n",
        "    def _find_layer_attr_path(self):\n",
        "        candidates = [[\"model\", \"layers\"], [\"transformer\", \"h\"], [\"model\", \"decoder\", \"layers\"]]\n",
        "        for path in candidates:\n",
        "            cur = self.model\n",
        "            valid = True\n",
        "            for p in path:\n",
        "                if hasattr(cur, p): cur = getattr(cur, p)\n",
        "                else: valid = False; break\n",
        "            if valid and isinstance(cur, (list, nn.ModuleList)): return path\n",
        "        raise AttributeError(\"Could not find transformer layer list in model.\")\n",
        "\n",
        "    def _get_layers_list(self):\n",
        "        cur = self.model\n",
        "        for p in self._layers_attr_path: cur = getattr(cur, p)\n",
        "        return list(cur)\n",
        "\n",
        "    def generate(self, prompt: str, max_new_tokens: int = 150, **kwargs) -> str:\n",
        "        tok = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
        "        out = self.model.generate(**tok, max_new_tokens=max_new_tokens, pad_token_id=self.tokenizer.pad_token_id, **kwargs)\n",
        "        full_text = self.tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "        if full_text.startswith(prompt):\n",
        "             return full_text[len(prompt):].strip()\n",
        "        return full_text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-vectors-hooks"
      },
      "source": [
        "## **Step 4**: Vector & Hook Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_mean_difference(pos: np.ndarray, neg: np.ndarray) -> np.ndarray:\n",
        "    diff = (pos - neg).mean(axis=0)\n",
        "    return diff / (np.linalg.norm(diff) + 1e-12)\n",
        "\n",
        "def compute_logistic_regression(pos: np.ndarray, neg: np.ndarray) -> np.ndarray:\n",
        "    X = np.vstack([pos, neg])\n",
        "    y = np.concatenate([np.ones(len(pos)), np.zeros(len(neg))])\n",
        "    clf = LogisticRegression(max_iter=1000).fit(X, y)\n",
        "    w = clf.coef_.reshape(-1)\n",
        "    return w / (np.linalg.norm(w) + 1e-12)\n",
        "\n",
        "def compute_pca_vector(pos: np.ndarray, neg: np.ndarray) -> np.ndarray:\n",
        "    diffs = pos - neg\n",
        "    pca = PCA(n_components=1).fit(np.vstack([diffs, -diffs]))\n",
        "    vec = pca.components_[0]\n",
        "    return vec / (np.linalg.norm(vec) + 1e-12)\n",
        "\n",
        "class SteeringHook:\n",
        "    def __init__(self, model, layer_path, layer_idx, style_vector, multiplier):\n",
        "        self.model, self.layer_path, self.layer_idx = model, layer_path, layer_idx\n",
        "        self.style_vector_cpu = torch.from_numpy(style_vector).float() * multiplier\n",
        "        self.handle = None\n",
        "        self._register_hook()\n",
        "\n",
        "    def _get_layer_module(self):\n",
        "        cur = self.model\n",
        "        for p in self.layer_path: cur = getattr(cur, p)\n",
        "        idx = self.layer_idx if self.layer_idx >= 0 else len(cur) + self.layer_idx\n",
        "        return cur[idx]\n",
        "\n",
        "    def _hook(self, module, input, output):\n",
        "        tensor_output = output[0] if isinstance(output, tuple) else output\n",
        "        add_vec = self.style_vector_cpu.to(tensor_output.device, dtype=tensor_output.dtype)\n",
        "        modified_tensor = tensor_output + add_vec.view(1, 1, -1)\n",
        "        return (modified_tensor,) + output[1:] if isinstance(output, tuple) else modified_tensor\n",
        "\n",
        "    def _register_hook(self):\n",
        "        self.handle = self._get_layer_module().register_forward_hook(self._hook)\n",
        "\n",
        "    def remove(self):\n",
        "        if self.handle: self.handle.remove()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-data-load-2"
      },
      "source": [
        "## **Step 5**: Data Loading Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_for_training_and_testing(file_path: str):\n",
        "    \"\"\"\n",
        "    Loads data from the XLSX file, creates dynamic prompts,\n",
        "    and returns a training set (all 40) and a test set (first 20).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_excel(file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # --- Check your column names here ---\n",
        "    NEUTRAL_COL = 'response_Neutral'\n",
        "    STYLED_COL = 'response_styled'\n",
        "    # -----------------------------------\n",
        "\n",
        "    required_cols = ['date', 'Time', 'Venue', 'OccasionType', 'Host', 'Event', NEUTRAL_COL, STYLED_COL]\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        print(f\"Error: Missing one of the required columns. Found: {df.columns}\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"INFO: Loaded {len(df)} examples from the file.\")\n",
        "\n",
        "    train_examples = []\n",
        "    test_examples = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        date = row.get('date', 'N/A')\n",
        "        time_ = row.get('Time', 'N/A')\n",
        "        venue = row.get('Venue', 'N/A')\n",
        "        occasion = row.get('OccasionType', 'N/A')\n",
        "        host = row.get('Host', 'N/A')\n",
        "        event = row.get('Event', 'N/A')\n",
        "        \n",
        "        neutral_email = row.get(NEUTRAL_COL)\n",
        "        styled_email = row.get(STYLED_COL)\n",
        "\n",
        "        if pd.isna(neutral_email) or pd.isna(styled_email):\n",
        "            continue\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Write an email inviting participants to the following event.\n",
        "Ensure the email tone matches the style instruction and stays under 100 words.\n",
        "\n",
        "Event Details:\n",
        "- Date: {date}\n",
        "- Time: {time_}\n",
        "- Venue: {venue}\n",
        "- Occasion Type: {occasion}\n",
        "- Host: {host}\n",
        "- Event: {event}\n",
        "\"\"\"\n",
        "        # Add to training set (all examples)\n",
        "        train_examples.append((prompt, styled_email, neutral_email))\n",
        "\n",
        "        # Add to test set (first 20 examples)\n",
        "        if idx < 20:\n",
        "            test_examples.append((prompt, styled_email))\n",
        "\n",
        "    print(f\"Using {len(train_examples)} for training and {len(test_examples)} for testing.\")\n",
        "    \n",
        "    train_hist = {\"user_1\": train_examples} \n",
        "    test_hist = {\"user_1\": test_examples} \n",
        "\n",
        "    return train_hist, test_hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-run-evaluation"
      },
      "source": [
        "## **Step 6**: Run Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Evaluation: model=meta-llama/Llama-2-7b-hf, layer=-15\n",
            "INFO: Loaded 41 examples from the file.\n",
            "Using 41 for training and 20 for testing.\n",
            "Activations loaded successfully from 'activations.npz'\n",
            "[Pipeline] Computed style vectors.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f69562eec2354b84a5068498b2aadbac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ModelGenerator] Model loaded. Path: ['model', 'layers'], Layers: 32\n",
            "\n",
            "==================================================\n",
            "Automated Evaluation on 20 Test Examples\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating on test set: 100%|██████████| 20/20 [2:48:59<00:00, 506.97s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Evaluation Results (Average F1-Score)\n",
            "==================================================\n",
            "Method     | Avg. ROUGE-L    | Avg. METEOR    \n",
            "------------------------------------------\n",
            "MEAN       | 0.1635          | 0.1608         \n",
            "LOGREG     | 0.1523          | 0.1609         \n",
            "PCA        | 0.1795          | 0.1847         \n",
            "\n",
            "Pipeline finished successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    if 'ipykernel' in sys.modules: sys.argv = sys.argv[:1]\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--model\", type=str, default=\"meta-llama/Llama-2-7b-hf\")\n",
        "    parser.add_argument(\"--layer\", type=int, default=-15)\n",
        "    parser.add_argument(\"--xlsx_file\", type=str, default=\"generated_email_responses (1).xlsx\")\n",
        "    parser.add_argument(\"--input_file\", type=str, default=\"activations.npz\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(f\"Running Evaluation: model={args.model}, layer={args.layer}\")\n",
        "\n",
        "    # 1. Load test data (we only need the test set here)\n",
        "    _, test_hist = load_data_for_training_and_testing(args.xlsx_file)\n",
        "    if not test_hist:\n",
        "        print(\"Halting execution due to data loading error.\")\n",
        "    else:\n",
        "        # 2. Load the saved activations\n",
        "        try:\n",
        "            data = np.load(args.input_file)\n",
        "            pos_arr = data['pos_acts']\n",
        "            neg_arr = data['neg_acts']\n",
        "            print(f\"Activations loaded successfully from '{args.input_file}'\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: The file '{args.input_file}' was not found.\")\n",
        "            print(\"Please run the '1_Extract_Activations.ipynb' script first.\")\n",
        "            sys.exit(1)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred loading activations: {e}\")\n",
        "            sys.exit(1)\n",
        "\n",
        "        # 3. Compute Style Vectors\n",
        "        user_style_vectors = {\n",
        "            \"mean\": compute_mean_difference(pos_arr, neg_arr),\n",
        "            \"logreg\": compute_logistic_regression(pos_arr, neg_arr),\n",
        "            \"pca\": compute_pca_vector(pos_arr, neg_arr)\n",
        "        }\n",
        "        print(\"[Pipeline] Computed style vectors.\")\n",
        "\n",
        "        # 4. Load the model for generation\n",
        "        ae_gen = ModelGenerator(args.model)\n",
        "\n",
        "        # 5. Run Automated Evaluation\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"Automated Evaluation on {len(test_hist['user_1'])} Test Examples\")\n",
        "        print(\"=\"*50)\n",
        "        \n",
        "        scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "        scores = {\n",
        "            \"mean\": {\"rougeL\": [], \"meteor\": []},\n",
        "            \"logreg\": {\"rougeL\": [], \"meteor\": []},\n",
        "            \"pca\": {\"rougeL\": [], \"meteor\": []}\n",
        "        }\n",
        "        \n",
        "        test_examples = test_hist[\"user_1\"]\n",
        "        \n",
        "        for (inp_prompt, ideal_user_email) in tqdm(test_examples, desc=\"Evaluating on test set\"):\n",
        "            \n",
        "            ideal_email_cleaned = ideal_user_email.replace(inp_prompt, \"\").strip()\n",
        "            ideal_tokens = nltk.word_tokenize(ideal_email_cleaned)\n",
        "            if not ideal_tokens: ideal_tokens = [\"\"]\n",
        "\n",
        "            for method, style_vec in user_style_vectors.items():\n",
        "                hook = SteeringHook(ae_gen.model, ae_gen._layers_attr_path, args.layer, style_vec, 2.0)\n",
        "                try:\n",
        "                    steered_out_full = ae_gen.generate(inp_prompt, temperature=0.7, do_sample=True, top_p=0.9)\n",
        "                    steered_out_cleaned = steered_out_full.replace(inp_prompt, \"\").strip()\n",
        "\n",
        "                    rouge_scores = scorer.score(ideal_user_email, steered_out_full)\n",
        "                    scores[method][\"rougeL\"].append(rouge_scores['rougeL'].fmeasure)\n",
        "                    \n",
        "                    steered_tokens = nltk.word_tokenize(steered_out_cleaned)\n",
        "                    if not steered_tokens: steered_tokens = [\"\"]\n",
        "                    meteor = meteor_score([ideal_tokens], steered_tokens)\n",
        "                    scores[method][\"meteor\"].append(meteor)\n",
        "                    \n",
        "                finally:\n",
        "                    hook.remove()\n",
        "\n",
        "        # 6. Print Final Results\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Evaluation Results (Average F1-Score)\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"{'Method':<10} | {'Avg. ROUGE-L':<15} | {'Avg. METEOR':<15}\")\n",
        "        print(\"-\" * 42)\n",
        "        \n",
        "        for method in scores.keys():\n",
        "            avg_rouge = np.mean(scores[method]['rougeL'])\n",
        "            avg_meteor = np.mean(scores[method]['meteor'])\n",
        "            print(f\"{method.upper():<10} | {avg_rouge:<15.4f} | {avg_meteor:<15.4f}\")\n",
        "\n",
        "        print(\"\\nPipeline finished successfully.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
